{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing Libraries\n",
    "import selenium\n",
    "import pandas as pd\n",
    "import time\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# Importing selenium webdriver \n",
    "from selenium import webdriver\n",
    "\n",
    "# Importing required Exceptions which needs to handled\n",
    "from selenium.common.exceptions import StaleElementReferenceException, NoSuchElementException\n",
    "\n",
    "#Importing requests\n",
    "import requests\n",
    "\n",
    "# importing regex\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Chrome(r'C:\\Users\\USER\\Desktop\\Project_flip_robo\\chromedriver.exe')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "url=\"https://timesofindia.indiatimes.com/archive/year-2017,month-2.cms\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get(url)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "TOI={}\n",
    "TOI['Date']=[]\n",
    "TOI['Author']=[]\n",
    "TOI['Vertical']=[]\n",
    "TOI['Headline']=[]\n",
    "TOI['Description']=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "urls=[]\n",
    "news_urls=[]\n",
    "start_page = 0\n",
    "end_page = 27"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "for page in range(start_page,end_page+1):\n",
    "    try:\n",
    "        page_urls = driver.find_elements_by_xpath('//td[@align=\"center\"]/a')\n",
    "        for url in page_urls:\n",
    "            url = url.get_attribute('href')\n",
    "            urls.append(url)\n",
    "    except StaleElementReferenceException as e:             # Handling StaleElement Exception   \n",
    "        print(\"Stale Exception\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "for url in urls[:28]:\n",
    "    driver.get(url)\n",
    "    try:\n",
    "        news_url=driver.find_elements_by_xpath('/html/body/div[1]/table[2]/tbody/tr[2]/td[1]/div[3]/table/tbody/tr[2]/td[1]/span/a')\n",
    "        for url in news_url:\n",
    "            url = url.get_attribute('href')\n",
    "            news_urls.append(url)\n",
    "    except StaleElementReferenceException as e:             # Handling StaleElement Exception   \n",
    "        print(\"Stale Exception\") \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for url in news_urls:\n",
    "    driver.get(url)\n",
    "    time.sleep(2)\n",
    "    try:\n",
    "        date=driver.find_elements_by_name('//div[@class=\"_3R_Dd\"]/div')       #Extracting Name from xpath\n",
    "        TOI['Date'].append(brand.text)\n",
    "    except NoSuchElementException:\n",
    "        TOI['Date'].append('-')\n",
    "    \n",
    "    try:\n",
    "        author= driver.find_element_by_xpath('//a[@class=\"auth_detail\"]')      # Extracting Name from xpath\n",
    "        TOI['Author'].append(author.text)\n",
    "    except NoSuchElementException:\n",
    "        TOI['Author'].append('-')\n",
    "    \n",
    "    try:\n",
    "        vertical = driver.find_element_by_xpath('//li[@class=\"_1XODn _1ydrE\"]/a')  # Extracting vertical from xpath\n",
    "        TOI['Vertical'].append(vertical.text)\n",
    "    except NoSuchElementException:\n",
    "        TOI['Vertical'].append('-')\n",
    "        \n",
    "    try:\n",
    "        headline = driver.find_element_by_xpath('//h1[@class=\"_23498\"]')     # Extracting no. of Ratings from xpath\n",
    "        TOI['Headline'].append(headline.text)\n",
    "    except NoSuchElementException:\n",
    "        TOI['Headline'].append('-')\n",
    "        \n",
    "    try:\n",
    "        descrp = driver.find_element_by_xpath('//div[@class=\"ga-headlines\"]')     # Extracting no. of Ratings from xpath\n",
    "        TOI['Description'].append(descrp.text)\n",
    "    except NoSuchElementException:\n",
    "        TOI['Description'].append('-')\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "TOI_news = pd.DataFrame.from_dict(TOI)\n",
    "print(TOI_news)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
